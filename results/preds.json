{
  "psf__requests-2931": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "psf__requests-2931",
    "model_patch": "diff --git a/requests/models.py b/requests/models.py\nindex 9c624d3..2b9d0d2 100644\n--- a/requests/models.py\n+++ b/requests/models.py\n@@ -80,7 +80,9 @@ class RequestEncodingMixin(object):\n         if parameters are supplied as a dict.\n         \"\"\"\n \n-        if isinstance(data, (str, bytes)):\n+        if isinstance(data, bytes):\n+            return data\n+        if isinstance(data, str):\n             return to_native_string(data)\n         elif hasattr(data, 'read'):\n             return data\n@@ -846,3 +848,4 @@ class Response(object):\n             return self.raw.close()\n \n         return self.raw.release_conn()\n+\n"
  },
  "sympy__sympy-24213": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sympy__sympy-24213",
    "model_patch": "diff --git a/sympy/physics/units/unitsystem.py b/sympy/physics/units/unitsystem.py\nindex a436880c4b..38fc38be02 100644\n--- a/sympy/physics/units/unitsystem.py\n+++ b/sympy/physics/units/unitsystem.py\n@@ -175,7 +175,7 @@ def _collect_factor_and_dimension(self, expr):\n             for addend in expr.args[1:]:\n                 addend_factor, addend_dim = \\\n                     self._collect_factor_and_dimension(addend)\n-                if dim != addend_dim:\n+                if not self.get_dimension_system().equivalent_dims(dim, addend_dim):\n                     raise ValueError(\n                         'Dimension of \"{}\" is {}, '\n                         'but it should be {}'.format(\n@@ -203,3 +203,4 @@ def get_units_non_prefixed(self) -> tSet[Quantity]:\n         Return the units of the system that do not have a prefix.\n         \"\"\"\n         return set(filter(lambda u: not u.is_prefixed and not u.is_physical_constant, self._units))\n+\n"
  },
  "django__django-13297": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-13297",
    "model_patch": "diff --git a/django/views/generic/base.py b/django/views/generic/base.py\nindex ea5baca08d..57f54951c3 100644\n--- a/django/views/generic/base.py\n+++ b/django/views/generic/base.py\n@@ -159,8 +159,15 @@ class TemplateView(TemplateResponseMixin, ContextMixin, View):\n     def get(self, request, *args, **kwargs):\n         # RemovedInDjango40Warning: when the deprecation ends, replace with:\n         #   context = self.get_context_data()\n+        # Pass the real URL kwargs to get_context_data() so user code receives\n+        # the actual values (not SimpleLazyObject). Add deprecated context\n+        # variables wrapped in SimpleLazyObject to the returned context only\n+        # when the user didn't already provide them.\n+        context = self.get_context_data(**kwargs)\n         context_kwargs = _wrap_url_kwargs_with_deprecation_warning(kwargs)\n-        context = self.get_context_data(**context_kwargs)\n+        for key, value in context_kwargs.items():\n+            if key not in context:\n+                context[key] = value\n         return self.render_to_response(context)\n \n \n@@ -238,3 +245,4 @@ class RedirectView(View):\n \n     def patch(self, request, *args, **kwargs):\n         return self.get(request, *args, **kwargs)\n+\n"
  },
  "django__django-13810": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-13810",
    "model_patch": "diff --git a/django/core/handlers/base.py b/django/core/handlers/base.py\nindex 8e8c3da06a..bfe85ddc07 100644\n--- a/django/core/handlers/base.py\n+++ b/django/core/handlers/base.py\n@@ -50,12 +50,14 @@ class BaseHandler:\n             else:\n                 middleware_is_async = middleware_can_async\n             try:\n-                # Adapt handler, if needed.\n-                handler = self.adapt_method_mode(\n+                # Adapt handler, if needed. Use a local adapted_handler so that\n+                # MiddlewareNotUsed raised by the middleware factory does not\n+                # leave handler overwritten and poison the middleware chain.\n+                adapted_handler = self.adapt_method_mode(\n                     middleware_is_async, handler, handler_is_async,\n                     debug=settings.DEBUG, name='middleware %s' % middleware_path,\n                 )\n-                mw_instance = middleware(handler)\n+                mw_instance = middleware(adapted_handler)\n             except MiddlewareNotUsed as exc:\n                 if settings.DEBUG:\n                     if str(exc):\n@@ -346,3 +348,4 @@ def reset_urlconf(sender, **kwargs):\n \n \n request_finished.connect(reset_urlconf)\n+\n"
  },
  "django__django-11179": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-11179",
    "model_patch": "diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\nindex 92fe4affb9..c0d0989068 100644\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -277,6 +277,10 @@ class Collector:\n             if self.can_fast_delete(instance):\n                 with transaction.mark_for_rollback_on_error():\n                     count = sql.DeleteQuery(model).delete_batch([instance.pk], self.using)\n+                # Clear the primary key attribute on the instance to reflect that it\n+                # has been deleted (consistent with the behavior in the general case\n+                # below where instance PKs are set to None after deletion).\n+                setattr(instance, model._meta.pk.attname, None)\n                 return count, {model._meta.label: count}\n \n         with transaction.atomic(using=self.using, savepoint=False):\n@@ -325,3 +329,4 @@ class Collector:\n             for instance in instances:\n                 setattr(instance, model._meta.pk.attname, None)\n         return sum(deleted_counter.values()), dict(deleted_counter)\n+\n"
  },
  "django__django-14011": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-14011",
    "model_patch": "diff --git a/django/core/servers/basehttp.py b/django/core/servers/basehttp.py\nindex 14dab517c9..7075efa3ec 100644\n--- a/django/core/servers/basehttp.py\n+++ b/django/core/servers/basehttp.py\n@@ -79,7 +79,7 @@ class WSGIServer(simple_server.WSGIServer):\n \n class ThreadedWSGIServer(socketserver.ThreadingMixIn, WSGIServer):\n     \"\"\"A threaded version of the WSGIServer\"\"\"\n-    daemon_threads = True\n+    daemon_threads = False\n \n \n class ServerHandler(simple_server.ServerHandler):\n@@ -213,3 +213,4 @@ def run(addr, port, wsgi_handler, ipv6=False, threading=False, server_cls=WSGISe\n         httpd.daemon_threads = True\n     httpd.set_app(wsgi_handler)\n     httpd.serve_forever()\n+\n"
  },
  "django__django-7530": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-7530",
    "model_patch": "diff --git a/django/core/management/commands/makemigrations.py b/django/core/management/commands/makemigrations.py\nindex 0b39536f5b..387e977e6f 100644\n--- a/django/core/management/commands/makemigrations.py\n+++ b/django/core/management/commands/makemigrations.py\n@@ -105,7 +105,7 @@ class Command(BaseCommand):\n                     # At least one model must be migrated to the database.\n                     router.allow_migrate(connection.alias, app_label, model_name=model._meta.object_name)\n                     for app_label in consistency_check_labels\n-                    for model in apps.get_models(app_label)\n+                    for model in apps.get_app_config(app_label).get_models()\n             )):\n                 loader.check_consistent_history(connection)\n \n@@ -320,3 +320,4 @@ class Command(BaseCommand):\n                         \"Full merge migrations file '%s':\" % writer.filename) + \"\\n\"\n                     )\n                     self.stdout.write(\"%s\\n\" % writer.as_string())\n+\n"
  },
  "astropy__astropy-7166": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "astropy__astropy-7166",
    "model_patch": "diff --git a/astropy/utils/misc.py b/astropy/utils/misc.py\nindex de3fb01d1..510640916 100644\n--- a/astropy/utils/misc.py\n+++ b/astropy/utils/misc.py\n@@ -528,14 +528,49 @@ class InheritDocstrings(type):\n                 not key.startswith('_'))\n \n         for key, val in dct.items():\n-            if (inspect.isfunction(val) and\n-                is_public_member(key) and\n-                val.__doc__ is None):\n-                for base in cls.__mro__[1:]:\n-                    super_method = getattr(base, key, None)\n-                    if super_method is not None:\n-                        val.__doc__ = super_method.__doc__\n-                        break\n+            if not is_public_member(key):\n+                continue\n+\n+            # Determine the underlying callable whose __doc__ should be filled.\n+            target = None\n+            if inspect.isfunction(val):\n+                target = val\n+            elif isinstance(val, classmethod):\n+                target = val.__func__\n+            elif isinstance(val, staticmethod):\n+                target = val.__func__\n+            elif isinstance(val, property):\n+                target = val.fget\n+\n+            # If we don't have a target (e.g., some other descriptor), skip.\n+            if target is None:\n+                continue\n+\n+            # Only fill in missing docstrings.\n+            if getattr(target, '__doc__', None):\n+                continue\n+\n+            for base in cls.__mro__[1:]:\n+                super_method = getattr(base, key, None)\n+                if super_method is None:\n+                    continue\n+\n+                # Extract docstring from the superclass' attribute, handling\n+                # descriptors like classmethod/staticmethod/property.\n+                if isinstance(super_method, classmethod) or isinstance(super_method, staticmethod):\n+                    doc = getattr(super_method.__func__, '__doc__', None)\n+                elif isinstance(super_method, property):\n+                    doc = getattr(super_method.fget, '__doc__', None)\n+                else:\n+                    doc = getattr(super_method, '__doc__', None)\n+\n+                if doc:\n+                    try:\n+                        target.__doc__ = doc\n+                    except Exception:\n+                        # In the unlikely event the __doc__ cannot be set, ignore.\n+                        pass\n+                    break\n \n         super().__init__(name, bases, dct)\n \n@@ -1127,3 +1162,4 @@ def dtype_bytes_or_chars(dtype):\n     match = re.search(r'(\\d+)$', dtype.str)\n     out = int(match.group(1)) if match else None\n     return out\n+\n"
  },
  "django__django-16662": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-16662",
    "model_patch": "diff --git a/django/db/migrations/writer.py b/django/db/migrations/writer.py\nindex a59f0c8dcb..c0f2d9173e 100644\n--- a/django/db/migrations/writer.py\n+++ b/django/db/migrations/writer.py\n@@ -173,9 +173,20 @@ class MigrationWriter:\n         else:\n             imports.add(\"from django.db import migrations\")\n \n-        # Sort imports by the package / module to be imported (the part after\n-        # \"from\" in \"from ... import ...\" or after \"import\" in \"import ...\").\n-        sorted_imports = sorted(imports, key=lambda i: i.split()[1])\n+        # Sort imports so plain \"import ...\" come before \"from ... import ...\",\n+        # and then sort by the module/package name. This matches Django's\n+        # import style and isort defaults.\n+        def _import_key(i):\n+            parts = i.split()\n+            # parts[0] is 'import' or 'from', parts[1] is the module name for 'import'\n+            # and the module for 'from'.\n+            if parts[0] == \"import\":\n+                return (0, parts[1])\n+            if parts[0] == \"from\":\n+                return (1, parts[1])\n+            return (2, i)\n+\n+        sorted_imports = sorted(imports, key=_import_key)\n         items[\"imports\"] = \"\\n\".join(sorted_imports) + \"\\n\" if imports else \"\"\n         if migration_imports:\n             items[\"imports\"] += (\n@@ -309,3 +320,4 @@ class Migration(migrations.Migration):\n %(operations)s\\\n     ]\n \"\"\"\n+\n"
  },
  "sphinx-doc__sphinx-9658": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9658",
    "model_patch": "diff --git a/sphinx/ext/autodoc/mock.py b/sphinx/ext/autodoc/mock.py\nindex b562f47fd..0c7aa7935 100644\n--- a/sphinx/ext/autodoc/mock.py\n+++ b/sphinx/ext/autodoc/mock.py\n@@ -34,7 +34,15 @@ class _MockObject:\n             superclass = args[1][-1].__class__\n             if superclass is cls:\n                 # subclassing MockObject\n-                return _make_subclass(args[0], superclass.__display_name__,\n+                # superclass.__display_name__ may include the class name (e.g.\n+                # 'torch.nn.Module'), but __module__ should be only the module\n+                # (e.g. 'torch.nn'). Extract the module part if present.\n+                display = getattr(superclass, '__display_name__', '')\n+                if display and '.' in display:\n+                    module = display.rsplit('.', 1)[0]\n+                else:\n+                    module = display\n+                return _make_subclass(args[0], module,\n                                       superclass=superclass, attributes=args[2])\n \n         return super().__new__(cls)\n@@ -185,3 +193,4 @@ def undecorate(subject: _MockObject) -> Any:\n         return subject.__sphinx_decorator_args__[0]\n     else:\n         return subject\n+\n"
  },
  "django__django-10973": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-10973",
    "model_patch": "diff --git a/django/db/backends/postgresql/client.py b/django/db/backends/postgresql/client.py\nindex 7fca6eff30..e5cf264fc9 100644\n--- a/django/db/backends/postgresql/client.py\n+++ b/django/db/backends/postgresql/client.py\n@@ -2,7 +2,6 @@ import os\n import signal\n import subprocess\n \n-from django.core.files.temp import NamedTemporaryFile\n from django.db.backends.base.client import BaseDatabaseClient\n \n \n@@ -34,38 +33,22 @@ class DatabaseClient(BaseDatabaseClient):\n             args += ['-p', str(port)]\n         args += [dbname]\n \n-        temp_pgpass = None\n         sigint_handler = signal.getsignal(signal.SIGINT)\n         try:\n+            env = None\n             if passwd:\n-                # Create temporary .pgpass file.\n-                temp_pgpass = NamedTemporaryFile(mode='w+')\n-                try:\n-                    print(\n-                        _escape_pgpass(host) or '*',\n-                        str(port) or '*',\n-                        _escape_pgpass(dbname) or '*',\n-                        _escape_pgpass(user) or '*',\n-                        _escape_pgpass(passwd),\n-                        file=temp_pgpass,\n-                        sep=':',\n-                        flush=True,\n-                    )\n-                    os.environ['PGPASSFILE'] = temp_pgpass.name\n-                except UnicodeEncodeError:\n-                    # If the current locale can't encode the data, let the\n-                    # user input the password manually.\n-                    pass\n+                # Pass password via PGPASSWORD environment variable to psql.\n+                env = os.environ.copy()\n+                env['PGPASSWORD'] = passwd\n             # Allow SIGINT to pass to psql to abort queries.\n             signal.signal(signal.SIGINT, signal.SIG_IGN)\n-            subprocess.check_call(args)\n+            # Use subprocess.run with a custom environment (available in Python 3.5+).\n+            subprocess.run(args, env=env, check=True)\n         finally:\n             # Restore the original SIGINT handler.\n             signal.signal(signal.SIGINT, sigint_handler)\n-            if temp_pgpass:\n-                temp_pgpass.close()\n-                if 'PGPASSFILE' in os.environ:  # unit tests need cleanup\n-                    del os.environ['PGPASSFILE']\n \n     def runshell(self):\n         DatabaseClient.runshell_db(self.connection.get_connection_params())\n+\n+\n"
  },
  "sphinx-doc__sphinx-9230": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9230",
    "model_patch": "diff --git a/sphinx/ext/napoleon/docstring.py b/sphinx/ext/napoleon/docstring.py\nindex d8cb75a5f..c748c7011 100644\n--- a/sphinx/ext/napoleon/docstring.py\n+++ b/sphinx/ext/napoleon/docstring.py\n@@ -264,10 +264,20 @@ class GoogleDocstring:\n         _name, _type, _desc = before, '', after\n \n         if parse_type:\n+            # First, try matching \"name(type)\" (Google style, e.g. \"arg(str)\")\n             match = _google_typed_arg_regex.match(before)\n-            if match:\n+            # Ensure the matched parentheses are at the end of the \"before\" string.\n+            # This avoids misinterpreting type-first signatures like\n+            # \"dict(str, str) opc_meta\" as name=\"dict\" and type=\"str, str\".\n+            if match and match.end() == len(before):\n                 _name = match.group(1).strip()\n                 _type = match.group(2)\n+            else:\n+                # Try matching \"type name\" (reST style, e.g. \":param dict(str, str) name:\")\n+                m2 = re.match(r'^\\s*(\\S+\\(.*\\)|\\S+)\\s+(.+)$', before)\n+                if m2:\n+                    _type = m2.group(1).strip()\n+                    _name = m2.group(2).strip()\n \n         _name = self._escape_args_and_kwargs(_name)\n \n@@ -1336,3 +1346,4 @@ class NumpyDocstring(GoogleDocstring):\n         lines += ['']\n \n         return self._format_admonition('seealso', lines)\n+\n"
  },
  "psf__requests-1921": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "psf__requests-1921",
    "model_patch": "diff --git a/requests/sessions.py b/requests/sessions.py\nindex a023e4e..e1b4bf5 100644\n--- a/requests/sessions.py\n+++ b/requests/sessions.py\n@@ -54,8 +54,8 @@ def merge_setting(request_setting, session_setting, dict_class=OrderedDict):\n     merged_setting = dict_class(to_key_val_list(session_setting))\n     merged_setting.update(to_key_val_list(request_setting))\n \n-    # Remove keys that are set to None.\n-    for (k, v) in request_setting.items():\n+    # Remove keys that are set to None in either the request or the session.\n+    for (k, v) in list(merged_setting.items()):\n         if v is None:\n             del merged_setting[k]\n \n"
  },
  "django__django-12406": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-12406",
    "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex dafc11f995..52bbf95f5f 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -13,7 +13,7 @@ from django.forms.forms import BaseForm, DeclarativeFieldsMetaclass\n from django.forms.formsets import BaseFormSet, formset_factory\n from django.forms.utils import ErrorList\n from django.forms.widgets import (\n-    HiddenInput, MultipleHiddenInput, SelectMultiple,\n+    HiddenInput, MultipleHiddenInput, SelectMultiple, RadioSelect,\n )\n from django.utils.text import capfirst, get_text_list\n from django.utils.translation import gettext, gettext_lazy as _\n@@ -1185,7 +1185,15 @@ class ModelChoiceField(ChoiceField):\n                  required=True, widget=None, label=None, initial=None,\n                  help_text='', to_field_name=None, limit_choices_to=None,\n                  **kwargs):\n-        if required and (initial is not None):\n+        # RadioSelect widgets have an inherent \"unfilled\" state, so for\n+        # required ModelChoiceFields using RadioSelect we don't provide an\n+        # explicit empty_label option which would otherwise render as a\n+        # selectable \"---------\" choice (and may appear selected).\n+        is_radio = False\n+        if widget is not None:\n+            # widget may be a widget class or an instance\n+            is_radio = (widget is RadioSelect) or isinstance(widget, RadioSelect)\n+        if required and (initial is not None or is_radio):\n             self.empty_label = None\n         else:\n             self.empty_label = empty_label\n@@ -1381,3 +1389,5 @@ def modelform_defines_fields(form_class):\n         form_class._meta.fields is not None or\n         form_class._meta.exclude is not None\n     )\n+\n+\n"
  },
  "django__django-16631": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-16631",
    "model_patch": "diff --git a/django/contrib/auth/__init__.py b/django/contrib/auth/__init__.py\nindex 155330c596..696d2caac7 100644\n--- a/django/contrib/auth/__init__.py\n+++ b/django/contrib/auth/__init__.py\n@@ -5,7 +5,7 @@ from django.apps import apps as django_apps\n from django.conf import settings\n from django.core.exceptions import ImproperlyConfigured, PermissionDenied\n from django.middleware.csrf import rotate_token\n-from django.utils.crypto import constant_time_compare\n+from django.utils.crypto import constant_time_compare, salted_hmac\n from django.utils.module_loading import import_string\n from django.views.decorators.debug import sensitive_variables\n \n@@ -21,6 +21,34 @@ def load_backend(path):\n     return import_string(path)()\n \n \n+def _session_hash_matches_user(session_hash, user):\n+    \"\"\"\n+    Return True if session_hash matches the user's session auth hash\n+    using the current SECRET_KEY or any SECRET_KEY_FALLBACKS.\n+    \"\"\"\n+    if not session_hash:\n+        return False\n+    # Compare against the current key first.\n+    try:\n+        current_hash = user.get_session_auth_hash()\n+    except Exception:\n+        return False\n+    if constant_time_compare(session_hash, current_hash):\n+        return True\n+    # Compare against fallback secret keys. SECRET_KEY_FALLBACKS may be None.\n+    fallbacks = getattr(settings, \"SECRET_KEY_FALLBACKS\", []) or []\n+    for secret in fallbacks:\n+        fallback_hash = salted_hmac(\n+            \"django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash\",\n+            user.password,\n+            secret=secret,\n+            algorithm=\"sha256\",\n+        ).hexdigest()\n+        if constant_time_compare(session_hash, fallback_hash):\n+            return True\n+    return False\n+\n+\n def _get_backends(return_tuples=False):\n     backends = []\n     for backend_path in settings.AUTHENTICATION_BACKENDS:\n@@ -106,8 +134,8 @@ def login(request, user, backend=None):\n     if SESSION_KEY in request.session:\n         if _get_user_session_key(request) != user.pk or (\n             session_auth_hash\n-            and not constant_time_compare(\n-                request.session.get(HASH_SESSION_KEY, \"\"), session_auth_hash\n+            and not _session_hash_matches_user(\n+                request.session.get(HASH_SESSION_KEY, \"\"), user\n             )\n         ):\n             # To avoid reusing another user's session, create a new, empty\n@@ -199,9 +227,7 @@ def get_user(request):\n             # Verify the session\n             if hasattr(user, \"get_session_auth_hash\"):\n                 session_hash = request.session.get(HASH_SESSION_KEY)\n-                session_hash_verified = session_hash and constant_time_compare(\n-                    session_hash, user.get_session_auth_hash()\n-                )\n+                session_hash_verified = _session_hash_matches_user(session_hash, user)\n                 if not session_hash_verified:\n                     request.session.flush()\n                     user = None\n@@ -228,3 +254,8 @@ def update_session_auth_hash(request, user):\n     request.session.cycle_key()\n     if hasattr(user, \"get_session_auth_hash\") and request.user == user:\n         request.session[HASH_SESSION_KEY] = user.get_session_auth_hash()\n+\n+\n+\n+\n+\n"
  },
  "pytest-dev__pytest-7490": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "pytest-dev__pytest-7490",
    "model_patch": "diff --git a/src/_pytest/nodes.py b/src/_pytest/nodes.py\nindex 560548aea..46bd49c4c 100644\n--- a/src/_pytest/nodes.py\n+++ b/src/_pytest/nodes.py\n@@ -282,6 +282,20 @@ class Node(metaclass=NodeMeta):\n         else:\n             self.own_markers.insert(0, marker_.mark)\n \n+        # Invalidate cached skip/xfail evaluation results when markers change.\n+        # These StoreKeys are defined in _pytest.skipping to cache evaluation\n+        # results during setup/runtest. If a marker is added dynamically at\n+        # runtime (e.g., in a fixture), we need to remove cached values so that\n+        # the new marker is considered.\n+        try:\n+            from _pytest.skipping import skipped_by_mark_key, xfailed_key, unexpectedsuccess_key\n+        except Exception:\n+            # If skipping module isn't available for some reason, skip cache invalidation.\n+            return\n+        for key in (skipped_by_mark_key, xfailed_key, unexpectedsuccess_key):\n+            if key in self._store:\n+                del self._store[key]\n+\n     def iter_markers(self, name: Optional[str] = None) -> Iterator[Mark]:\n         \"\"\"\n         :param name: if given, filter the results by the name attribute\ndiff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py\nindex 335e10996..ad1d72d07 100644\n--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -262,6 +262,12 @@ def pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n     outcome = yield\n     rep = outcome.get_result()\n     xfailed = item._store.get(xfailed_key, None)\n+    # If no cached evaluation is present (for example because a marker was added\n+    # dynamically during the test run via request.node.add_marker), re-evaluate\n+    # xfail marks now so the report can take them into account.\n+    if xfailed is None:\n+        xfailed = evaluate_xfail_marks(item)\n+        item._store[xfailed_key] = xfailed\n     # unittest special case, see setting of unexpectedsuccess_key\n     if unexpectedsuccess_key in item._store and rep.when == \"call\":\n         reason = item._store[unexpectedsuccess_key]\n@@ -313,3 +319,4 @@ def pytest_report_teststatus(report: BaseReport) -> Optional[Tuple[str, str, str\n         elif report.passed:\n             return \"xpassed\", \"X\", \"XPASS\"\n     return None\n+\ndiff --git a/test_xfail_dynamic.py b/test_xfail_dynamic.py\nnew file mode 100644\nindex 000000000..71d3ed4e5\n--- /dev/null\n+++ b/test_xfail_dynamic.py\n@@ -0,0 +1,6 @@\n+import pytest\n+\n+def test_xfail_test(request):\n+    mark = pytest.mark.xfail(reason=\"xfail\")\n+    request.node.add_marker(mark)\n+    assert 0\n"
  },
  "scikit-learn__scikit-learn-26323": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "scikit-learn__scikit-learn-26323",
    "model_patch": "diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py\nindex 4eddd12b1..617799d65 100644\n--- a/sklearn/compose/_column_transformer.py\n+++ b/sklearn/compose/_column_transformer.py\n@@ -303,6 +303,18 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n         for trans in transformers:\n             _safe_set_output(trans, transform=transform)\n \n+        # If remainder is an estimator (and not the special 'passthrough' or\n+        # 'drop' strings), ensure its output config is also set. This covers\n+        # calling set_output before fit, where the remainder estimator is not\n+        # part of self.transformers yet.\n+        if getattr(self, \"remainder\", None) not in {\"passthrough\", \"drop\"}:\n+            try:\n+                _safe_set_output(self.remainder, transform=transform)\n+            except Exception:\n+                # Be defensive: if remainder is not an estimator or setting output\n+                # fails for any reason, ignore to preserve original behavior.\n+                pass\n+\n         return self\n \n     def get_params(self, deep=True):\n@@ -1142,3 +1154,4 @@ class make_column_selector:\n         if self.pattern is not None:\n             cols = cols[cols.str.contains(self.pattern, regex=True)]\n         return cols.tolist()\n+\n"
  },
  "sympy__sympy-17655": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sympy__sympy-17655",
    "model_patch": "diff --git a/sympy/geometry/point.py b/sympy/geometry/point.py\nindex 7c978c47be..e087bd6af6 100644\n--- a/sympy/geometry/point.py\n+++ b/sympy/geometry/point.py\n@@ -21,7 +21,7 @@\n \n import warnings\n \n-from sympy.core import S, sympify, Expr\n+from sympy.core import S, sympify, Expr, Mul\n from sympy.core.compatibility import is_sequence\n from sympy.core.containers import Tuple\n from sympy.simplify import nsimplify, simplify\n@@ -213,6 +213,21 @@ def __add__(self, other):\n         sympy.geometry.point.Point.translate\n \n         \"\"\"\n+        # Handle expressions like scalar*Point (e.g., 2*Point(1, 1))\n+        # by extracting the Point factor and converting the Mul into a\n+        # proper Point instance before proceeding.\n+        if isinstance(other, Mul):\n+            for factor in other.args:\n+                if isinstance(factor, Point):\n+                    scalar = other / factor\n+                    try:\n+                        other = factor * scalar\n+                    except Exception:\n+                        # If something unexpected happens, fall back to\n+                        # the original behavior below which will raise.\n+                        pass\n+                    break\n+\n         try:\n             s, o = Point._normalize_dimension(self, Point(other, evaluate=False))\n         except TypeError:\n@@ -1349,3 +1364,4 @@ def z(self):\n         1\n         \"\"\"\n         return self.args[2]\n+\n"
  },
  "django__django-14053": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-14053",
    "model_patch": "diff --git a/django/contrib/staticfiles/storage.py b/django/contrib/staticfiles/storage.py\nindex 494890cc23..4d9569127a 100644\n--- a/django/contrib/staticfiles/storage.py\n+++ b/django/contrib/staticfiles/storage.py\n@@ -226,17 +226,28 @@ class HashedFilesMixin:\n             path for path in paths\n             if matches_patterns(path, self._patterns)\n         ]\n+\n+        # Track which original names we've yielded back to the caller so we\n+        # don't yield the same original filename multiple times across the\n+        # multiple post-process passes. Exceptions are always yielded so errors\n+        # are not suppressed.\n+        yielded = set()\n+\n         # Do a single pass first. Post-process all files once, then repeat for\n         # adjustable files.\n         for name, hashed_name, processed, _ in self._post_process(paths, adjustable_paths, hashed_files):\n-            yield name, hashed_name, processed\n+            if isinstance(processed, Exception) or name not in yielded:\n+                yield name, hashed_name, processed\n+                yielded.add(name)\n \n         paths = {path: paths[path] for path in adjustable_paths}\n \n         for i in range(self.max_post_process_passes):\n             substitutions = False\n             for name, hashed_name, processed, subst in self._post_process(paths, adjustable_paths, hashed_files):\n-                yield name, hashed_name, processed\n+                if isinstance(processed, Exception) or name not in yielded:\n+                    yield name, hashed_name, processed\n+                    yielded.add(name)\n                 substitutions = substitutions or subst\n \n             if not substitutions:\n@@ -439,3 +450,4 @@ class ConfiguredStorage(LazyObject):\n \n \n staticfiles_storage = ConfiguredStorage()\n+\n"
  },
  "sphinx-doc__sphinx-7590": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-7590",
    "model_patch": "diff --git a/sphinx/domains/cpp.py b/sphinx/domains/cpp.py\nindex fe52d881d..94ff8193f 100644\n--- a/sphinx/domains/cpp.py\n+++ b/sphinx/domains/cpp.py\n@@ -4658,16 +4658,23 @@ class DefinitionParser(BaseParser):\n             return ASTBooleanLiteral(True)\n         if self.skip_word('false'):\n             return ASTBooleanLiteral(False)\n+        # permissive UDL matcher: ident-like, possibly ::-qualified (e.g., q_J or my::udl)\n+        udl_re = re.compile(r'(?:[A-Za-z_][A-Za-z0-9_]*(?:::[A-Za-z_][A-Za-z0-9_]*)*)')\n         for regex in [float_literal_re, binary_literal_re, hex_literal_re,\n                       integer_literal_re, octal_literal_re]:\n             pos = self.pos\n             if self.match(regex):\n                 while self.current_char in 'uUlLfF':\n                     self.pos += 1\n+                # consume an optional user-defined-literal suffix (if present)\n+                self.match(udl_re)\n                 return ASTNumberLiteral(self.definition[pos:self.pos])\n \n         string = self._parse_string()\n         if string is not None:\n+            # after a string literal a UDL suffix may follow, consume it if present\n+            if self.match(udl_re):\n+                string = string + self.last_match.group()\n             return ASTStringLiteral(string)\n \n         # character-literal\n"
  }
}